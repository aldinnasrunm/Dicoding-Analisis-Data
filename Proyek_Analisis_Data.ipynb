{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9wADwK78DCz"
   },
   "source": [
    "# Proyek Analisis Data: Air Quality Dataset\n",
    "- **Nama:** Aldin Nasrun Minalloh\n",
    "- **Email:** m268d4ky3374@bangkit.academy\n",
    "- **ID Dicoding:** aldinnasrunm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eE0raob58DC0"
   },
   "source": [
    "## Menentukan Pertanyaan Bisnis\n",
    "- Apakah ada tren yang terjadi pada setiap kolom?\n",
    "- Apakah ada bulan-bulan tertentu yang memiliki tren peningkatan atau penurunan?\n",
    "- Sebutkan korelasi antar kolom yang terkuat dan terlemah?\n",
    "- Bagaimana distribusi setiap kolom apakah normal atau tidak?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "- No : row number\n",
    "- year : year of data in this row\n",
    "- month : month of data in this row\n",
    "- day : day of data in this row\n",
    "- hour : hour of data in this row\n",
    "- PM2.5 : PM2.5 concentration (ug/m^3)\n",
    "- PM10 : PM10 concentration (ug/m^3)\n",
    "- SO2 : SO2 concentration (ug/m^3)\n",
    "- NO2 : NO2 concentration (ug/m^3)\n",
    "- CO : CO concentration (ug/m^3)\n",
    "- O3 : Ozone concentration (ug/m^3)\n",
    "- TEMP : temperature (degree Celsius)\n",
    "- PRES : pressure (hPa)\n",
    "- DEWP : dew point temperature (degree Celsius)\n",
    "- RAIN : precipitation (mm)\n",
    "- wd : wind direction\n",
    "- WSPM : wind speed (m/s)\n",
    "- station : name of the air-quality monitoring site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-z4QGlO8DC1"
   },
   "source": [
    "## Import Semua Packages/Library yang Digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_Sh51Xy8DC1"
   },
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXU2GBYu8DC1"
   },
   "source": [
    "### Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Aotizhongxin = pd.read_csv('data/PRSA_Data_Aotizhongxin_20130301-20170228.csv')\n",
    "df_Changping = pd.read_csv('data/PRSA_Data_Changping_20130301-20170228.csv')\n",
    "df_Dingling = pd.read_csv('data/PRSA_Data_Dingling_20130301-20170228.csv')\n",
    "df_Dongsi = pd.read_csv('data/PRSA_Data_Dongsi_20130301-20170228.csv')\n",
    "df_Guanyuan = pd.read_csv('data/PRSA_Data_Guanyuan_20130301-20170228.csv')\n",
    "df_Gucheng = pd.read_csv('data/PRSA_Data_Gucheng_20130301-20170228.csv')\n",
    "df_Huairou = pd.read_csv('data/PRSA_Data_Huairou_20130301-20170228.csv')\n",
    "df_Nongzhanguan = pd.read_csv('data/PRSA_Data_Nongzhanguan_20130301-20170228.csv')\n",
    "df_Shunyi = pd.read_csv('data/PRSA_Data_Shunyi_20130301-20170228.csv')\n",
    "df_Tiantan = pd.read_csv('data/PRSA_Data_Tiantan_20130301-20170228.csv')\n",
    "df_Wanliu = pd.read_csv('data/PRSA_Data_Wanliu_20130301-20170228.csv')\n",
    "df_Wanshouxigong = pd.read_csv('data/PRSA_Data_Wanshouxigong_20130301-20170228.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat dataframe\n",
    "\n",
    "df_all = pd.concat([df_Aotizhongxin, df_Changping, df_Dingling, df_Dongsi, df_Guanyuan, df_Gucheng, df_Huairou, df_Nongzhanguan, df_Shunyi, df_Tiantan, df_Wanliu, df_Wanshouxigong])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHSiqaZp8DC1"
   },
   "source": [
    "### Assessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhN5R4hr8DC1"
   },
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Column No\n",
    "\n",
    "karena kolom ini tidak digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(columns=['No'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Missing values imputation Function\n",
    "\n",
    "Sebuah function yang berfungsi untuk menimpute misssing value beberapa column. Di mana nilai yang diinput di ambil dari nilai mean yang sudah di kelompokkan berdasarkan stasiun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_imputation(dataframe, column):\n",
    "    df_groupby_column = dataframe.groupby(by='station')[column].mean().reset_index()\n",
    "    \n",
    "    Aotizhongxin =  df_groupby_column.iloc[0][column]\n",
    "    Changping =  df_groupby_column.iloc[1][column]\n",
    "    Dingling =  df_groupby_column.iloc[2][column]\n",
    "    Dongsi =  df_groupby_column.iloc[3][column]\n",
    "    Guanyuan =  df_groupby_column.iloc[4][column]\n",
    "    Gucheng =  df_groupby_column.iloc[5][column]\n",
    "    Huairou =  df_groupby_column.iloc[6][column]\n",
    "    Nongzhanguan =  df_groupby_column.iloc[7][column]\n",
    "    Shunyi =  df_groupby_column.iloc[8][column]\n",
    "    Tiantan =  df_groupby_column.iloc[9][column]\n",
    "    Wanliu =  df_groupby_column.iloc[10][column]\n",
    "    Wanshouxigong =  df_groupby_column.iloc[11][column]\n",
    "    \n",
    "    df_null = dataframe[dataframe[column].isna()]\n",
    "    df_not_null = dataframe[dataframe[column].notna()]\n",
    "\n",
    "    data_impute = []\n",
    "\n",
    "    for i in df_null['station']:\n",
    "        if i == 'Aotizhongxin':\n",
    "            data_impute.append(Aotizhongxin)\n",
    "        elif i == 'Changping':\n",
    "            data_impute.append(Changping)\n",
    "        elif i == 'Dingling':\n",
    "            data_impute.append(Dingling)\n",
    "        elif i == 'Dongsi':\n",
    "            data_impute.append(Dongsi)\n",
    "        elif i == 'Guanyuan':\n",
    "            data_impute.append(Guanyuan)\n",
    "        elif i == 'Gucheng':\n",
    "            data_impute.append(Gucheng)\n",
    "        elif i == 'Huairou':\n",
    "            data_impute.append(Huairou)\n",
    "        elif i == 'Nongzhanguan':\n",
    "            data_impute.append(Nongzhanguan)\n",
    "        elif i == 'Shunyi':\n",
    "            data_impute.append(Shunyi)\n",
    "        elif i == 'Tiantan':\n",
    "            data_impute.append(Tiantan)\n",
    "        elif i == 'Wanliu':\n",
    "            data_impute.append(Wanliu)\n",
    "        elif i == 'Wanshouxigong':\n",
    "            data_impute.append(Wanshouxigong)\n",
    "\n",
    "    df_null[column] = data_impute\n",
    "\n",
    "    dataframe = pd.concat([df_not_null, df_null]).reset_index(drop=True)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = missing_values_imputation(df_all, 'PM2.5')\n",
    "df_all = missing_values_imputation(df_all, 'PM10')\n",
    "df_all = missing_values_imputation(df_all, 'SO2')\n",
    "df_all = missing_values_imputation(df_all, 'NO2')\n",
    "df_all = missing_values_imputation(df_all, 'CO')\n",
    "df_all = missing_values_imputation(df_all, 'O3')\n",
    "df_all = missing_values_imputation(df_all, 'TEMP')\n",
    "df_all = missing_values_imputation(df_all, 'PRES')\n",
    "df_all = missing_values_imputation(df_all, 'DEWP')\n",
    "df_all = missing_values_imputation(df_all, 'RAIN')\n",
    "df_all = missing_values_imputation(df_all, 'WSPM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values Imputation wd\n",
    "\n",
    "karena data type kolumn wd merupakan object jadi saya menggunakan nilai modus yang di kelompokkan berdasarkan stasiun untuk mengisi nilai missing values dari kolom wd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby(by='station')['wd'].agg(pd.Series.mode).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null = df_all[df_all['wd'].isna()]\n",
    "df_not_null = df_all[df_all['wd'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_impute = []\n",
    "\n",
    "for i in df_null['station']:\n",
    "    if i == 'Aotizhongxin':\n",
    "        data_impute.append('NE')\n",
    "    elif i == 'Changping':\n",
    "        data_impute.append('NNW')\n",
    "    elif i == 'Dingling':\n",
    "        data_impute.append('NNW')\n",
    "    elif i == 'Dongsi':\n",
    "        data_impute.append('ENE')\n",
    "    elif i == 'Guanyuan':\n",
    "        data_impute.append('NE')\n",
    "    elif i == 'Gucheng':\n",
    "        data_impute.append('N')\n",
    "    elif i == 'Huairou':\n",
    "        data_impute.append('NW')\n",
    "    elif i == 'Nongzhanguan':\n",
    "        data_impute.append('ENE')\n",
    "    elif i == 'Shunyi':\n",
    "        data_impute.append('NNE')\n",
    "    elif i == 'Tiantan':\n",
    "        data_impute.append('ENE')\n",
    "    elif i == 'Wanliu':\n",
    "        data_impute.append('NE')\n",
    "    elif i == 'Wanshouxigong':\n",
    "        data_impute.append('NE')\n",
    "\n",
    "df_null['wd'] = data_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_not_null, df_null]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping Data Based On year, month, day and station\n",
    "\n",
    "Data di kelompokkan berdasarkan year, month, day dan stasiun dan diambil nilai mean nya yang bertujuan untuk mendapatkan insight yang lebih jelas, karena kita hanya menggunakan padatan informasi untuk analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouping = df_all.groupby(by=['year', 'month','day','station'])[['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make New Date Column\n",
    "\n",
    "Untuk timiseries analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouping['date'] =  pd.to_datetime(df_grouping[['year', 'month', 'day']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop year, month, day, column\n",
    "\n",
    "Karena sudah tidak dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouping = df_grouping.drop(columns=['year', 'month','day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gp-Y6wU38DC1"
   },
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Heat Map Plot\n",
    "\n",
    "Untuk menampilkan korelasi antar kolum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df_grouping.drop(columns=['station', 'date']).corr(), cmap='coolwarm', annot=True) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan plot diatas dapat diambil kesimpulan :\n",
    "1. korelasi terkuat dimiliki oleh kolom PM2.5 dengan PM10 dengan korelasi 0.92.\n",
    "2. Korelasi terlemah dimiliki oleh kolom CO dan RAIN sebesar -0.037.\n",
    "3. Terdapat korelasi kuat antar kolum yang ditunjukkan oleh beberapa kolom seperti : PM2.5 dengan PM10, PM2.5 dengan CO PM2.5 dengan NO2, PM10 dengan CO, PM 10 dengan NO2, dan masih banyak lagi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distrbution Plot \n",
    "\n",
    "Untuk menampilkan distribusi tiap-tiap kolom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,4, figsize=(20,12))\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for i in df_grouping.drop(columns=['date']):\n",
    "    if col < 4:\n",
    "        sns.histplot(data=df_grouping.drop(columns=['date']), x=i, kde=True, ax=axes[row][col])\n",
    "        axes[row][col].set_title(f'Distribution of {i}')\n",
    "        col+=1\n",
    "    else:\n",
    "        col = 0\n",
    "        row+=1\n",
    "        sns.histplot(data=df_grouping.drop(columns=['date']), x=i, kde=True, ax=axes[row][col])\n",
    "        axes[row][col].set_title(f'Distribution of {i}')\n",
    "        col+=1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan plot diatas diambil kesimpulan : \n",
    "1. Semua plot berdistribusi tidak normal.\n",
    "2. Ada beberapa kolom yang memiliki distribusi mendekati normal seperti : TEMP, PRES dan DEWP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plot \n",
    "\n",
    "Untuk mengamati distribusi dan outlier dari setiap kolom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,4, figsize=(20,12))\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for i in df_grouping.drop(columns=['station', 'date']):\n",
    "    if col < 4:\n",
    "        sns.boxplot(data=df_grouping.drop(columns=['station', 'date']), y=i, ax=axes[row][col])\n",
    "        axes[row][col].set_title(f'Distribution of {i}')\n",
    "        col+=1\n",
    "    else:\n",
    "        col = 0\n",
    "        row+=1\n",
    "        sns.boxplot(data=df_grouping.drop(columns=['station', 'date']), y=i, ax=axes[row][col])\n",
    "        axes[row][col].set_title(f'Distribution of {i}')\n",
    "        col+=1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan plot diatas dapat diambil kesimpulan:\n",
    "1. Kebanyakan kolum memiliki outlier (skewness) yang menyatakan bahwa distribusi nya juga tidak normal.\n",
    "2. Beberapa kolom tidak memiliki outlier seperti TEMP, PRES dan DEWP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desctitive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouping.drop(columns=['station', 'date']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Analysis\n",
    "\n",
    "Melihat tren dari kolom terhadap waktu.\n",
    "\n",
    "Data dikelompokkan berdasarkan 4 stasiun agar insight lebih jelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Aotizhongxin_Changping_Dingling_Dongsi = df_grouping[(df_grouping['station'] == 'Aotizhongxin') | (df_grouping['station'] == 'Changping') | (df_grouping['station'] == 'Dingling') | (df_grouping['station'] == 'Dongsi')]\n",
    "df_Guanyuan_Gucheng_Huairou_Nongzhanguan = df_grouping[(df_grouping['station'] == 'Guanyuan') | (df_grouping['station'] == 'Gucheng') | (df_grouping['station'] == 'Huairou') | (df_grouping['station'] == 'Nongzhanguan')]\n",
    "df_Shunyi_Tiantan_Wanliu_Wanshouxigong = df_grouping[(df_grouping['station'] == 'Shunyi') | (df_grouping['station'] == 'Tiantan') | (df_grouping['station'] == 'Wanliu') | (df_grouping['station'] == 'Wanshouxigong')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = {\n",
    "    \"Aotizhongxin_Changping_Dingling_Dongsi\" : df_Aotizhongxin_Changping_Dingling_Dongsi,\n",
    "    \"Guanyuan_Gucheng_Huairou_Nongzhanguan\" : df_Guanyuan_Gucheng_Huairou_Nongzhanguan,\n",
    "    \"Shunyi_Tiantan_Wanliu_Wanshouxigong\" : df_Shunyi_Tiantan_Wanliu_Wanshouxigong\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi yang berfungsi menampilkan line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_line_plot(df, column, title):\n",
    "    plt.figure(figsize=(25,4))\n",
    "    sns.lineplot(data=df, x='date', y = column , hue='station')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PM2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_merge:\n",
    "    create_line_plot(df_merge[key], 'PM2.5', f'PM2.5 in {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan plot diatas tidak ada tren (semua nilai acak) yang di tunjunkkan oleh PM2.5 hal ini juga terjadi di semua station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PM10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_merge:\n",
    "    create_line_plot(df_merge[key], 'PM10', f'PM10 in {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan plot diatas tidak ada tren (semua nilai acak) yang di tunjunkkan oleh PM10 hal ini juga terjadi di semua station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_merge:\n",
    "    create_line_plot(df_merge[key], 'SO2', f'SO2 in {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan plot diatas pada SO2 terlihat tren naik ppada bulan 10 dan sampai puncaknya pada bulan 1. Lalu menurun pada bulan 2 sampai bulan 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_merge:\n",
    "    create_line_plot(df_merge[key], 'NO2', f'NO2 in {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan plot diatas pada NO2 terlihat tren naik ppada bulan 7 dan sampai puncaknya pada bulan 1. Lalu menurun pada bulan 2 sampai bulan 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_merge:\n",
    "    create_line_plot(df_merge[key], 'CO', f'CO in {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan plot diatas pada CO terdapat tren kenaikkan pada bulan 1 dan menurun di bulan berikutnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_merge:\n",
    "    create_line_plot(df_merge[key], 'O3', f'O3 in {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan plot diatas pada O3 terdapat tren kenaikan pada bulan 1 ke bulan 7 lalu terjadi penurunan dari bulan 7 ke bulan 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_merge:\n",
    "    create_line_plot(df_merge[key], 'TEMP', f'TEMP in {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan plot diatas pada TEMP terjadi tren naik pada bulan 1 ke bulan 7 dan penurunan di bukan 7 ke bulan 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_merge:\n",
    "    create_line_plot(df_merge[key], 'PRES', f'TEMP in {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan plot diatas pada PRES terdapat tren naik pada bulan 7 ke bulan 1 dan terjadi tren penurunan pada bulan 1 ke bulan 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEWP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_merge:\n",
    "    create_line_plot(df_merge[key], 'DEWP', f'DEWP in {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan plot diatas pada DEWP terdapat tren kenaikan pada bulan 1 ke bulan 7 dan terjadi tren penurunan di bulan 7 ke bulan 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_merge:\n",
    "    create_line_plot(df_merge[key], 'RAIN', f'RAIN in {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WSPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_merge:\n",
    "    create_line_plot(df_merge[key], 'WSPM', f'WSPM in {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan plot diatas tidak ada tren (semua nilai acak) yang di tunjunkkan oleh WSPM hal ini juga terjadi di semua station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsyZjqak8DC2"
   },
   "source": [
    "## Visualization & Explanatory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZxOiQ6n8DC2"
   },
   "source": [
    "### Pertanyaan 1:\n",
    "Apakah ada tren yang terjadi pada setiap kolom?\n",
    "\n",
    "<b>Jawaban : </b>\n",
    "\n",
    "Kebanyakan kolom memiliki tren meningkat lalu menurun seperti seasonal hal ini ditunjukkan oleh kolom : SO2, NO2, CO, O3, TEMP, PRES, DEWP, RAIN dan WSPM.\n",
    "\n",
    "Namun ada juga kolom yang tidak menunjukkan tren (semua nilai acak) seperti : PM2.5 dan PM10,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_line_plot(df_Aotizhongxin_Changping_Dingling_Dongsi, 'DEWP', 'DEWP in Aotizhongxin_Changping_Dingling_Dongsi')\n",
    "create_line_plot(df_Aotizhongxin_Changping_Dingling_Dongsi, 'PM2.5', 'PM2.5 in Aotizhongxin_Changping_Dingling_Dongsi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgHI7CiU8DC2"
   },
   "source": [
    "### Pertanyaan 2:\n",
    "\n",
    "Apakah ada bulan-bulan tertentu yang memiliki tren peningkatan atau penurunan?\n",
    "\n",
    "<b>Jawaban : </b>\n",
    "\n",
    "Kebanyakan tren terjadi dibulan 1 atau 7 baik peningkatan atau penurunan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_line_plot(df_Aotizhongxin_Changping_Dingling_Dongsi, 'DEWP', 'DEWP in Aotizhongxin_Changping_Dingling_Dongsi')\n",
    "create_line_plot(df_Aotizhongxin_Changping_Dingling_Dongsi, 'PRES', 'PRES in Aotizhongxin_Changping_Dingling_Dongsi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgHI7CiU8DC2"
   },
   "source": [
    "### Pertanyaan 3:\n",
    "\n",
    "Sebutkan korelasi antar kolom yang terkuat dan terlemah?\n",
    "\n",
    "<b>Jawaban : </b>\n",
    "- korelasi terkuat dimiliki oleh kolom PM2.5 dengan PM10 dengan korelasi 0.92.\n",
    "- Korelasi terlemah dimiliki oleh kolom CO dan RAIN sebesar -0.037."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df_grouping.drop(columns=['station', 'date']).corr(), cmap='coolwarm', annot=True) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgHI7CiU8DC2"
   },
   "source": [
    "### Pertanyaan 4:\n",
    "\n",
    "Bagaimana distribusi setiap kolom apakah normal atau tidak?\n",
    "\n",
    "<b>Jawaban : </b>\n",
    "\n",
    "setiap kolom memiliki distrbusi tidak normal namun ada beberapa kolom yang tidak memiliki outlier seperti : TEMP, PRES dan DEWP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,4, figsize=(20,12))\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for i in df_grouping.drop(columns=['date']):\n",
    "    if col < 4:\n",
    "        sns.histplot(data=df_grouping.drop(columns=['date']), x=i, kde=True, ax=axes[row][col])\n",
    "        axes[row][col].set_title(f'Distribution of {i}')\n",
    "        col+=1\n",
    "    else:\n",
    "        col = 0\n",
    "        row+=1\n",
    "        sns.histplot(data=df_grouping.drop(columns=['date']), x=i, kde=True, ax=axes[row][col])\n",
    "        axes[row][col].set_title(f'Distribution of {i}')\n",
    "        col+=1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WeHlCeX8DC2"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTcyR48Y8DC2"
   },
   "source": [
    "- Conclution pertanyaan 1 : Kebanyakan kolom memiliki tren meningkat lalu menurun seperti seasonal hal ini ditunjukkan oleh kolom : SO2, NO2, CO, O3, TEMP, PRES, DEWP, RAIN dan WSPM. \n",
    "Namun ada juga kolom yang tidak menunjukkan tren (semua nilai acak) seperti : PM2.5 dan PM.0,\n",
    "- Conclution pertanyaan : Kebanyakan tren terjadi dibulan 1 atau 7 baik peningkatan atau penurunan.\n",
    "- Conclution pertanyaan 3 : korelasi terkuat dimiliki oleh kolom PM2.5 dengan PM10 dengan korelasi 0.92. \n",
    "Korelasi terlemah dimiliki oleh kolom CO dan RAIN sebesar -0.037.\n",
    "- Conclution pertanyaan 4  setiap kolom memiliki distrbusi tidak normal namun ada beberapa kolom yang tidak memiliki outlier seperti : TEMP, PRES dan DEWP.: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering (K-Means)\n",
    "Mengclustering feature PM2.5 dan feature PM10 untuk mengkelompokkan kualitas udara berdasarkan kolom-kolom tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ubah menjadi bentuk array\n",
    "X = np.asarray(df_grouping[[\"PM2.5\", \"PM10\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range k dari Kmeans\n",
    "k = range(1, 10)\n",
    "inertia = [] \n",
    "for i in k:\n",
    "    model = KMeans(n_clusters = i, max_iter = 1000, random_state=0) # jumlah cluster akan di loop sebanyak k range(9 times)\n",
    "    model.fit(X)\n",
    "    inertia.append(model.inertia_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(inertia):\n",
    "    print(f'Iterasi {i} - inertia = {j}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot elbow curve\n",
    "plt.plot(k, inertia, \"o-\")\n",
    "plt.xlabel('k value')\n",
    "plt.ylabel('inertia sum squared error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_km = KMeans(n_clusters=4, max_iter= 1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouping['cluster_km'] = model_km.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(data=df_grouping, x='PM2.5', y='PM10', hue='cluster_km', palette='bright')\n",
    "sns.scatterplot(x=model_km.cluster_centers_[:, 0], y=model_km.cluster_centers_[:, 1], color='yellow', marker='X', s=300, label='Centroids')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouping.drop(columns=['cluster_km']).to_csv('dashboard/main_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "972b3bf27e332e87b5379f2791f6ef9dfc79c71018c370b0d7423235e20fe4d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
